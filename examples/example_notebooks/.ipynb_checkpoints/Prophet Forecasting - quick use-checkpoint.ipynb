{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f69b6e9-a8ff-4094-a008-d5878de1bb72",
   "metadata": {},
   "source": [
    "# Covid-19 forecasting using Prophet\n",
    "\n",
    "This project aims to utilize the Prophet library in Python to forecast COVID-19 cases, providing valuable insights into future trends.\n",
    "\n",
    "Methodology:\n",
    "\n",
    "1. Data Preparation: The COVID-19 dataset is loaded into a Pandas DataFrame and preprocessed to ensure consistency and accuracy.\n",
    "2. Time Series Analysis: The Prophet library is used to model the time series data, capturing both trend and seasonality.\n",
    "3. Model Training: The Prophet model is trained on historical COVID-19 case data to learn patterns and relationships.\n",
    "4. Forecasting: The trained model is used to generate forecasts for future COVID-19 cases based on the learned patterns.\n",
    "5. Evaluation: The accuracy of the forecasts is evaluated using metrics such as Mean Absolute Error (MAE) or Root Mean Squared Error (RMSE).\n",
    "6. Visualization: The forecasted COVID-19 cases are visualized using Matplotlib and Seaborn to provide intuitive insights into future trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913ebbf9-8aa5-43bf-a1cd-3930c4131bce",
   "metadata": {},
   "source": [
    "### Loading Libraries and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa0075-6013-4ecd-82b9-20c90b60d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import malib.data.clean as mc\n",
    "import malib.data.format as mf\n",
    "import malib.data.plotting as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c9e7d-dfc0-4622-a215-6a59fddcda6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../../data/raw/covid_19_clean_complete.csv\"\n",
    "DS = \"Date\"\n",
    "Y = \"Confirmed\"\n",
    "SAVE_PATH = \"../../data/processed/\"\n",
    "FILE_NAME = \"df_clean_target_confirmed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43ccba-c30f-4c89-86ff-6898fe4db7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_raw = pd.read_csv(PATH)\n",
    "\n",
    "# View the first few rows of the dataframe\n",
    "display(df_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566aaa0-f71a-4a57-b049-153207c804c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc1490-06ce-4f8f-b2cd-6f2fecb051e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date and target columns into model format required\n",
    "df = mf.format_date(df_raw,DS, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13244bde-45b5-4c9f-9f37-c5da80516a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef9332-e0ea-4b8d-9ea1-0e17b532546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.plot_time_series(df,DS,['Confirmed','Deaths','Recovered'],False,\"Temporal Evolution COVID-19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4cae34-7992-411e-b005-b2318bfb4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.plot_decompose_time_series(df, DS, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca8820c-822e-4051-9cb5-6838ab7ce796",
   "metadata": {},
   "source": [
    "### Analysis of the Graph\n",
    "\n",
    "1. **Original Series (Confirmed)**\n",
    "   - The first subplot shows the original time series of confirmed COVID-19 cases. Here, we can observe how the confirmed cases have varied over time.\n",
    "\n",
    "2. **Trend**\n",
    "   - The second subplot shows the long-term trend of the time series. This trend represents the general behavior of the number of confirmed cases without considering seasonal fluctuations and residuals.\n",
    "   - In this case, we can see that the trend is upward, indicating a continuous increase in the number of confirmed cases over time.\n",
    "\n",
    "3. **Seasonality**\n",
    "   - The third subplot shows the seasonal component of the time series. This component captures periodic variations that occur at regular intervals (e.g., weekly or monthly patterns).\n",
    "   - Here, we can see that there is a clear seasonality with a regular pattern of increase and decrease in confirmed cases, which seems to repeat over a certain period of time.\n",
    "\n",
    "4. **Residual**\n",
    "   - The fourth subplot shows the residual, which is the part of the time series that remains after removing the trend and seasonality. It represents random fluctuations and noise that are not explained by the other two components.\n",
    "   - In this case, the residuals show variations that do not follow a clear pattern and seem quite random, although with some significant fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a5809-4779-4a13-a3cd-3b782bc3e3f6",
   "metadata": {},
   "source": [
    "## Data Transform & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa658fd-16e3-4295-90ab-8ccd796b0f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANING_RULES = {\n",
    "    'del_negative': True, # Delete rows with negavites values in target column\n",
    "    'del_days': None,  # Delete days of weeks. i.e. 0 (mondays) 6 (sundays)\n",
    "    'del_zeros': None, # Delete rows with zeros in target column,\n",
    "    'log_transform': None # Transform column y into log\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7657e2-43fd-4f8f-81ec-86808641ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning dataset\n",
    "df = mc.clean_df(df,Y,CLEANING_RULES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b7018f-5b15-4154-b8c9-fde1ed94ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format into forecast dataframe\n",
    "df = mf.format_input_and_target(df,DS, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d089a2a-df21-4e93-98a9-7e729fc31ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by country and date\n",
    "df = mf.group_by_columns_and_sum(df,['ds'],['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea2a22-596a-4ccb-a842-f3af00da66f7",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning in Prophet Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524161b-cd70-4de3-9295-1d7c8c16ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split into train and test\n",
    "train,test = msp.get_train_test_by_date_ratio(df,[0.8,0.2],'ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f6551-d302-4e01-a09a-0d056c7eae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid IOPub date_rate error by disabling verbosity\n",
    "import logging\n",
    "logging.getLogger(\"prophet\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"cmdstanpy\").disabled=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb80f78-9117-410d-87fa-f05bc9be4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days_to_predict = msp.get_df_n_days(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc6f7c0-cec9-4e46-a2cd-8fecddc027b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = {\n",
    "    'initial': str(round(msp.get_df_n_days(train)/2,0)) + \" days\",\n",
    "    'period': '7 days',\n",
    "    'horizon': '7 days'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec494c2c-8f9a-480d-9d8a-abc6c74aa3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_HP_OPTUNA = \"../../data/processed/hyperparameters/hp_optuna.csv\"\n",
    "PATH_HP_HYPEROPT = \"../../data/processed/hyperparameters/hp_hyperopt.csv\"\n",
    "PATH_HP_PARAM_GRID = \"../../data/processed/hyperparameters/hp_param_grid.csv\"\n",
    "trials = 2000\n",
    "# results,df_optuna,df_hyperopt = mt.compare_optimizers(train, cutoff,trials)\n",
    "# df_optuna.to_csv(PATH_HP_OPTUNA)\n",
    "# df_hyperopt.to_csv(PATH_HP_HYPEROPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56c967-1edc-48e5-a40c-22324a6e0103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamters grid\n",
    "\n",
    "# params_grid = {  'growth': [\"linear\"], \n",
    "#                 'changepoints': [None], \n",
    "#                 'n_changepoints': [ 25,50,75], \n",
    "#                 'changepoint_range': [0.7,0.8,0.9],\n",
    "#                 'yearly_seasonality': [\"auto\"],\n",
    "#                 'weekly_seasonality': [\"auto\"],\n",
    "#                 'daily_seasonality': [\"auto\"],\n",
    "#                 'holidays': [None],\n",
    "#                 'seasonality_mode': ['multiplicative',\"additive\"],\n",
    "#                 'changepoint_prior_scale': [0.01, 0.05, 0.1, 0.3, 0.4, 0.5,0.6,0.7,0.8,0.9],\n",
    "#                 'seasonality_prior_scale': [0.01, 0.1, 1.0, 3.0, 5.0, 7.0, 8.0, 9.0, 10.0,20,50,80],\n",
    "#                 'holidays_prior_scale': [0.01, 0.1, 1.0, 2.0, 3.0, 5.0, 8.0,9.0, 10.0,30,50,70,90],\n",
    "#                 'mcmc_samples': [0],\n",
    "#                 'interval_width': [ 0.8,0.9],\n",
    "#                 'uncertainty_samples': [0]\n",
    "#               }\n",
    "\n",
    "\n",
    "# bp = mt.all_hyperparameters_tunning(train,params_grid)\n",
    "# bp.to_csv(PATH_HP_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08463aa6-95af-41df-9f29-67a599a0ce74",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af336ea8-1564-4a5d-939b-76fcf1132479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt = pd.read_csv(PATH_HP_OPTUNA)\n",
    "df_hyp = pd.read_csv(PATH_HP_HYPEROPT)\n",
    "df_pg = pd.read_csv(PATH_HP_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7771ff4-a6ff-4af6-be15-45e6ee80bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ 'growth',\n",
    "                'changepoints', \n",
    "                'n_changepoints', \n",
    "                'changepoint_range',\n",
    "                'yearly_seasonality',\n",
    "                'weekly_seasonality',\n",
    "                'daily_seasonality',\n",
    "                'holidays',\n",
    "                'seasonality_mode',\n",
    "                'changepoint_prior_scale',\n",
    "                'seasonality_prior_scale',\n",
    "                'holidays_prior_scale',\n",
    "                'mcmc_samples',\n",
    "                'interval_width',\n",
    "                'uncertainty_samples'\n",
    "          ]\n",
    "values = list(eval(df_pg['params'][0]))\n",
    "dfpg = pd.DataFrame([values], columns=columns)\n",
    "\n",
    "common_columns = dfpg.columns.intersection(df_opt.columns).intersection(df_hyp.columns)\n",
    "df_concat = pd.concat([dfpg[common_columns], df_opt[common_columns], df_hyp[common_columns]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fc0bbe-0471-4a77-ba78-5cbe6c69cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre las filas del DataFrame y entrenar un modelo para cada conjunto de parámetros\n",
    "models = []\n",
    "for index, row in df_concat.iterrows():\n",
    "    m = Prophet(\n",
    "        n_changepoints=int(row['n_changepoints']),\n",
    "        changepoint_range=row['changepoint_range'],\n",
    "        seasonality_mode=row['seasonality_mode'],\n",
    "        changepoint_prior_scale=row['changepoint_prior_scale'],\n",
    "        seasonality_prior_scale=row['seasonality_prior_scale'],\n",
    "        holidays_prior_scale=row['holidays_prior_scale'],\n",
    "        interval_width=row['interval_width']\n",
    "    )\n",
    "    m.fit(train)\n",
    "    models.append(m)\n",
    "    print(f\"Model {index + 1} trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3863da1a-63d6-477e-ab38-a8333fe7acff",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef00af-f2c5-4062-bf54-9c122e5cca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = {}\n",
    "hyper_opt_names = [\"params_grid\", \"optuna\", \"hyperopt\"]\n",
    "\n",
    "for index, m in enumerate(models):\n",
    "    future = m.make_future_dataframe(periods=num_days_to_predict)\n",
    "    f = m.predict(future)\n",
    "    f = f[['ds', 'yhat']].tail(num_days_to_predict)\n",
    "    \n",
    "    # Agregar cada predicción al diccionario usando la clave correspondiente de hyper_opt_names\n",
    "    forecast[hyper_opt_names[index]] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd4181-7d4b-402f-ba7d-cfd22a0469d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,f in forecast.items():\n",
    "    f.to_csv(f\"../../data/processed/prediction/{key}.csv\",index=False,float_format=\"%.2f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ma_ml]",
   "language": "python",
   "name": "conda-env-ma_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
